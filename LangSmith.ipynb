{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da7a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['LANGSMITH_TRACING'] = 'true'\n",
    "os.environ['LANGSMITH_ENDPOINT'] = \"https://eu.api.smith.langchain.com \"\n",
    "os.environ['LANGSMITH_API_KEY'] =  os.getenv('LANGSMITH_API_KEY') or getpass('Enter your LangSmith API Key: ')\n",
    "os.environ['LANGSMITH_PROJECT'] = 'LangChain-LangSmith-Demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d83228",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") or getpass(\n",
    "    \"Enter GOOGLE API Key: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aad08b6",
   "metadata": {},
   "source": [
    "By default, LangChain will trace LLM calls, chains, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35bec364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",       # choose appropriate model name\n",
    "    temperature=0.0\n",
    "    # you may add other parameters like max_tokens, etc.\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f897447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm(messages):\n",
    "    return llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6114be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--ed55ccae-8307-409b-815b-34099f30a106-0', usage_metadata={'input_tokens': 2, 'output_tokens': 32, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 23}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_llm(\"Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b2af3",
   "metadata": {},
   "source": [
    "However, it won't capture functions from outside of LangChain. LangSmith can trace functions that are not part of LangChain, we just need to add the `@traceable` decorator. Let's try this for a few simple functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ac9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "import random\n",
    "import time\n",
    "\n",
    "@traceable\n",
    "def generate_random_number():\n",
    "    return random.randint(0, 100)\n",
    "\n",
    "@traceable\n",
    "def generate_string_delay(input_string: str):\n",
    "    number = random.randint(1, 5)\n",
    "    time.sleep(number)\n",
    "    return f\"{input_string} ({number})\"\n",
    "\n",
    "@traceable\n",
    "def random_error():\n",
    "    number = random.randint(0, 1)\n",
    "    if number == 0:\n",
    "        raise ValueError(\"An error occurred!\")\n",
    "    else:\n",
    "        return \"No Error!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56932ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:34<00:00,  3.40s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    generate_random_number()\n",
    "    generate_string_delay(\"Hello\")\n",
    "    try:\n",
    "        random_error()\n",
    "    except ValueError as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c3252",
   "metadata": {},
   "source": [
    "We can also modify our traceable names if we'd like to make them more readable inside the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deae70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@traceable(name=\"Chitchat Maker\")\n",
    "def error_generation_function(question: str):\n",
    "    delay = random.randint(0, 3)\n",
    "    time.sleep(delay)\n",
    "    number = random.randint(0, 1)\n",
    "    if number == 0:\n",
    "        raise ValueError(\"Random error\")\n",
    "    else:\n",
    "        return \"I'm great how are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d526d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(2)):\n",
    "    try:\n",
    "        error_generation_function(\"How are you today?\")\n",
    "    except ValueError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
